import argparse
import file
import http
import json
import logging
import net
import netconf
import router_client
import time
import process
import xml
import yang
import yang.data
import yang.gdata
import yang.schema
import yang.xml
import schema_filter


# Constant for the wildcard (all modules) default module-set
ALL_MODULE_SET = "all"


def expect[T](a: ?T, ctx: str) -> T:
    if a is not None:
        return a
    raise ValueError("expected value (not None) for: {ctx}")


actor ContainerManager(proc_cap: process.ProcessCap, log_handler: logging.Handler):
    """Manages Docker containers for network devices"""

    # Set up logging
    logh = logging.Handler("ContainerManager")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    def start_container(platform: PlatformConfig, instance_id: str) -> str:
        """Start a Docker container for the given platform"""
        # Generate unique container name
        container_name = "netclics-%s-%s" % (platform.name.replace(" ", "-"), instance_id)

        # Build docker run command arguments
        # --name: container name
        # --rm: remove container when it stops
        # -p: publish ports (would map container ports to host ports)
        # Note: In production, we'd run in foreground to stop with our process
        # For now, just use a placeholder image since the actual startup is mocked
        # In a real implementation, we would handle the optional container_image properly
        docker_args = [
            "run",
            "--name", container_name,
            "--rm",
            "-d",  # Detached mode for now
            "placeholder-image"  # Temporary placeholder - not actually used since we don't run containers
        ]

        _log.info("Starting container", {"container_name": container_name, "platform": platform.name, "instance_id": instance_id})
        _log.debug("Docker command would be", {"command": "docker " + " ".join(docker_args)})

        # For now, just log the command we would run
        # In production, would execute: process.Process(proc_cap, "docker", docker_args, {})

        # Schedule health check
        after 2: _check_container_health(container_name, platform)

        return container_name

    def _check_container_health(container_name: str, platform: PlatformConfig):
        """Check if container is healthy and get its network info"""
        # In reality, would run: docker inspect <container_name>
        # This would be done with:
        # inspect_proc = process.Process(proc_cap, "docker", ["inspect", container_name], {})
        # Then parse the JSON output to get:
        # - Container state (running, health status)
        # - IP address from NetworkSettings.IPAddress
        # - Port mappings from NetworkSettings.Ports

        _log.debug("Checking container health", {"container_name": container_name, "platform": platform.name})
        # Would parse actual docker inspect output here

    def get_container_info(container_name: str) -> dict[str, str]:
        """Get container network information"""
        # In reality: docker inspect <container_name>
        # Returns mock data for now
        _log.debug("Getting container info", {"container_name": container_name})
        return {
            "ip": "172.17.0.10",
            "netconf_port": "32830",
            "ssh_port": "32822"
        }

    def stop_container(container_name: str):
        """Stop a Docker container"""
        # In reality, would run: docker stop <container_name>
        _log.info("Stopping container", {"container_name": container_name})
        # Since we use --rm, container will be removed automatically


actor SchemaRegistry(fc: file.FileCap):
    var store: dict[u64, yang.schema.DRoot] = {}

    def _list_hash(l: list[str]) -> u64:
        h = hasher()
        for le in l:
            h.update(le.encode())
        return h.finalize()

    def add_schema(yang_src: list[str], cb: proc(time.Duration, ?u64, ?Exception) -> None):
        sw = time.Stopwatch()
        content_hash = _list_hash(yang_src)
        if content_hash not in store:
            try:
                compiled_schema = yang.compile_with_cache(yang_src, strict_quoting=False, fc=fc)
                store[content_hash] = compiled_schema
            except Exception as e:
                # Schema compilation failed, return error
                cb(sw.elapsed(), None, e)
                return
        cb(sw.elapsed(), content_hash, None)

    def get_schema(content_hash) -> ?yang.schema.DRoot:
        if content_hash is not None:
            return store.get(content_hash)


class _SchemaId:
    def __init__(self, identifier: str, version: ?str, format: ?str):
        self.identifier = identifier
        self.version = version
        self.format = format

    def __repr__(self):
        return "(identifier={repr(self.identifier)}, version={repr(self.version)}, format={repr(self.format)})"

    def to_named_tuple(self):
        return (identifier=self.identifier, version=self.version, format=self.format)


extension _SchemaId (Hashable):
    def __eq__(self, other):
        return self.identifier == other.identifier and self.version == other.version and self.format == other.format

    def hash(self, h):
        self.identifier.hash(h)
        _version = self.version
        if _version is not None:
            _version.hash(h)
        else:
            "".hash(h)
        _format = self.format
        if _format is not None:
            _format.hash(h)
        else:
            "".hash(h)


actor DeviceInstance(auth: WorldCap, log_handler: logging.Handler, platform_name: str, platform: str, schema_registry,
                     container_id: str, ip_address: str,
                     netconf_port: int, ssh_port: int, instance_spec: ?InstanceSpec = None):
    """Actor representing a device instance that can process conversion requests"""
    var state = "starting"  # starting, ready, busy, stopping, error
    var started_at = 0  # Timestamp when started
    var last_used_at = 0  # Timestamp of last use
    var device_platform = platform  # Store platform type for use in methods
    var retry_delay = 5  # Retry delay in seconds for NETCONF connections
    var edit_config_retry_delay = 5  # Retry delay in seconds for NETCONF edit-config locked errors
    var edit_config_retry_attempts = 5  # Max attempts for edit-config retries on locked errors

    var capabilities: list[str] = []
    # Map module-sets which are include and exclude patterns to expanded YANG module names
    var expanded_module_sets: dict[str, set[_SchemaId]] = {}
    # Store compiled module-set schema hashes. The hash value is None for
    # schemas that have not yet compiled or have compilation errors.
    var compiled_schemas: dict[str, ?u64] = {}
    # Track schema compilation errors for module-set
    var compiled_schemas_errors: dict[str, str] = {}

    # Raw downloaded schemas, I guess we could expose these via API?
    var schema_dict: dict[_SchemaId, str] = {}

    # Persistent clients for conversion operations (reused throughout conversion)
    var conversion_netconf_client: ?netconf.Client = None
    var conversion_cli_client: ?router_client.Client = None

    # Set up logging
    logh = logging.Handler("DeviceInstance [{container_id}]")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    def is_static_instance() -> bool:
        """Check if this is a static instance (vs dynamically created container)"""
        if instance_spec is not None:
            return True
        return False

    def get_state() -> str:
        return state

    def set_state(new_state: str):
        state = new_state

    def get_info() -> dict[str, ?value]:
        """Get device information for API responses"""
        instance_data = {
            "platform_name": platform_name,
            "platform": device_platform,
            "instance_id": container_id,
            "ip_address": ip_address,
            "state": state,
            "netconf_port": netconf_port,
            "ssh_port": ssh_port,
            "instance_type": "static" if is_static_instance() else "container"
        }
        if instance_spec is not None:
            desc = instance_spec.description
            if desc is not None:
                instance_data["description"] = desc

        msi = {}
        for name, schema_hash in compiled_schemas.items():
            # This logic is equivalent to get_compiled_schema(), but we avoid
            # actually fetching the schema, just check the error state
            if schema_hash is not None:
                msi[name] = {"compiled": True, "error": None}
            elif name in compiled_schemas_errors:
                msi[name] = {"compiled": False, "error": compiled_schemas_errors[name]}
            else:
                msi[name] = {"compiled": False, "error": "Schema not compiled"}
        instance_data["module_sets"] = msi

        return instance_data

    def get_compiled_schema(module_set_name) -> (?yang.schema.DRoot, ?str):
        h = compiled_schemas.get(module_set_name)
        if h is not None:
            return (schema_registry.get_schema(h), None)
        elif module_set_name in compiled_schemas_errors:
            return (None, compiled_schemas_errors[module_set_name])
        else:
            return (None, "Schema not compiled")

    def target_datastore():
        # In order of preference, we have these alternative commit procedures:
        # - write directly to running, if writable-running is supported
        # - write to candidate + commit
        if has_writable_running():
            return "running"
        elif has_candidate():
            return "candidate"

        raise ValueError("No writable datastore available")

    def has_candidate():
        return "urn:ietf:params:netconf:capability:candidate:1.0" in capabilities

    def has_writable_running():
        return "urn:ietf:params:netconf:capability:writable-running:1.0" in capabilities

    def create_netconf_client_with_retry(username: str, password: str, on_success: action(netconf.Client) -> None, on_failure: ?action(Exception) -> None=None, max_retries: ?int = None):
        """Create a NETCONF client with automatic retry on connection failure

        Args:
            username: Username for authentication
            password: Password for authentication
            on_success: Callback when connection succeeds
            on_failure: Callback when connection fails (only used if max_retries is set)
            max_retries: Maximum number of retries (None for unlimited)
        """
        def attempt_connection(retry_count=0):
            _log.info("Attempting NETCONF connection", {"attempt": retry_count, "host": ip_address, "port": netconf_port, "unlimited": True if max_retries is None else False})

            def on_connect(client: ?netconf.Client, error: ?Exception):
                if error is not None:
                    _log.warning("NETCONF connection attempt failed", {"attempt": retry_count, "error": str(error)})
                    if max_retries is not None and retry_count >= max_retries:
                        _log.error("Max retries reached", {"max_retries": max_retries})
                        if on_failure is not None:
                            on_failure(Exception(f"Failed to connect after {max_retries} attempts: {error}"))
                    else:
                        after float(retry_delay): attempt_connection(retry_count+1)
                elif client is not None:
                    _log.info("NETCONF connection successful", {"attempt": retry_count})
                    capabilities = client.get_capabilities()
                    on_success(client)

            # Create new client for this attempt
            netconf.Client(
                auth=auth,
                on_connect=on_connect,
                on_notif=None,
                address=ip_address,
                username=username,
                key=None,
                password=password,
                port=netconf_port,
                log_handler=log_handler,
                skip_host_key_check=True
            )

        # Start the first connection attempt
        attempt_connection()

    def _get_credentials() -> ?(str, str):
        """Get device credentials, returns (username, password) tuple or None"""
        _log.debug("Checking device credentials")
        if instance_spec is not None:
            _log.debug("InstanceSpec found")
            _username = instance_spec.username
            _password = instance_spec.password
            _log.debug("Checking username and password")
            if _username is not None and _password is not None:
                username = _username
                password = _password
                _log.info("Credentials found", {"username": username})
                return (username, password)
            else:
                _log.error("Missing username or password for device", {"device": container_id, "username": str(_username), "password_set": str(True if _password is not None else False)})
                return None
        else:
            _log.error("No InstanceSpec available for device", {"device": container_id})
            return None

    def validate_module_set(module_set: str) -> ?str:
        """Validate if the requested module_set is available. Returns error message if invalid, None if valid."""
        if module_set == "":
            # Empty module_set is valid (uses default)
            return None
        if module_set not in compiled_schemas:
            available_sets = list(compiled_schemas.keys())
            return "Invalid module_set: '{module_set}'. Available module sets: {', '.join(available_sets)}"
        return None

    def _is_locked_edit_config_error(error: netconf.NetconfError) -> bool:
        rpc_error = error.rpc_error
        if rpc_error is not None:
            for re in rpc_error:
                if re.error_tag == "in-use" or re.error_app_tag == "locked":
                    return True
        return False

    def _edit_config_with_retry(client: netconf.Client, config: list[xml.Node], cb: action(netconf.Client, ?netconf.NetconfError) -> None, datastore: str="running", default_operation: ?str=None):
        def attempt_edit(attempt: int):
            def on_edit_done(c: netconf.Client, error: ?netconf.NetconfError):
                if error is not None and _is_locked_edit_config_error(error) and attempt < edit_config_retry_attempts:
                    _log.warning("Edit-config locked; retrying", {"attempt": attempt, "max_attempts": edit_config_retry_attempts, "delay_seconds": edit_config_retry_delay, "error": error})
                    after float(edit_config_retry_delay): attempt_edit(attempt + 1)
                    return
                cb(c, error)
            client.edit_config(config, on_edit_done, datastore, default_operation=default_operation)
        attempt_edit(1)

    def _rollback_to_config(base_xml, base_gdata, final_gdata, result_callback: action(?Exception) -> None):
        """Rollback device configuration to a previous state"""
        _log.info("DeviceInstance.rollback called", {"device": container_id})
        if platform == "cisco_iosxe":
            backward_diff = yang.gdata.diff(final_gdata, base_gdata)
            if backward_diff is not None:
                target_config = backward_diff.to_xml()
            else:
                result_callback()
                return
        else:
            # Extract children without <data> wrapper for rollback
            target_config = base_xml.children
        config_preview = xml.encode_nodes(target_config)[:200]
        _log.debug("Extracted config for rollback", {"config_preview": config_preview})

        state = "busy"

        # Get credentials
        creds = _get_credentials()
        if creds is not None:
            username, password = creds
        else:
            state = "ready"
            result_callback(Exception("No credentials available"))
            return

        _log.info("Starting NETCONF rollback", {"username": username, "host": ip_address, "port": netconf_port})

        def on_connect_success(client: netconf.Client):
            _log.info("NETCONF client connected successfully for rollback")

            def on_edit_config_done(client: netconf.Client, error: ?netconf.NetconfError):
                _log.debug("Rollback edit-config response received")
                if error is not None:
                    _log.error("Rollback edit-config failed with NETCONF error", {"error": error})
                    client.close()
                    state = "ready"
                    result_callback(Exception(f"NETCONF rollback edit-config error: {error}"))
                else:
                    _log.info("Rollback edit-config completed successfully")

                    # Now commit the rollback
                    _log.debug("Sending rollback commit request")
                    client.commit(on_commit_done)

            def on_commit_done(client: netconf.Client, error: ?netconf.NetconfError):
                _log.debug("Rollback commit response received")
                if error is not None:
                    _log.error("Rollback commit failed with NETCONF error", {"error": error})
                    client.close()
                    state = "ready"
                    result_callback(Exception(f"NETCONF rollback commit error: {error}"))
                else:
                    _log.info("Rollback commit completed successfully")
                    client.close()
                    state = "ready"
                    result_callback(None)

            if platform == "cisco_iosxe":
                # On Cisco IOS XE we merge the running with with a computed diff
                op = None
            else:
                # On all other platforms we replace the config with base
                op = "replace"
            _edit_config_with_retry(client, target_config, on_edit_config_done if has_candidate() else on_commit_done, target_datastore(), default_operation=op)

        def on_connect_failure(error: Exception):
            _log.error("NETCONF rollback connection failed after retries", {"error": str(error)})
            state = "ready"
            result_callback(error)

        # Create NETCONF client for rollback (limited retries)
        _log.info("Creating NETCONF client connection for rollback")
        create_netconf_client_with_retry(username, password, on_connect_success, on_connect_failure, max_retries=5)

    def _clear_iosxe_archive_log(callback: action(?Exception) -> None):
        """Clear the IOS XE archive log to ensure clean configuration state"""
        _log.info("Clearing IOS XE archive log")

        def on_client_success(client: router_client.Client):
            _log.debug("CLI client ready, clearing archive log")
            def on_clear_complete(err: ?Exception, response: ?str):
                if err is not None:
                    _log.warning("Failed to clear archive log", {"error": str(err)})
                else:
                    _log.info("Archive log cleared successfully")
                callback(None)
            client.cmd(on_clear_complete, "clear archive log config force")

        def on_client_error(error: Exception):
            _log.error("Failed to get CLI client for archive clearing", {"error": str(error)})
            callback(error)

        _get_or_create_cli_client(on_client_success, on_client_error)

    def _get_or_create_netconf_client(on_success: action(netconf.Client) -> None, on_error: action(Exception) -> None):
        """Get existing NETCONF client or create a new one for conversion operations"""
        nc_client = conversion_netconf_client
        if nc_client is not None:
            _log.debug("Reusing existing NETCONF client for conversion")
            on_success(nc_client)
        else:
            _log.info("Creating new NETCONF client for conversion")
            creds = _get_credentials()
            if creds is not None:
                username, password = creds
            else:
                on_error(Exception("No credentials available"))
                return

            def on_connect_success(client: netconf.Client):
                conversion_netconf_client = client
                _log.info("NETCONF client created and stored for reuse")
                on_success(client)

            def on_connect_failure(error: Exception):
                _log.error("Failed to create NETCONF client", {"error": str(error)})
                on_error(error)

            create_netconf_client_with_retry(username, password, on_connect_success, on_connect_failure, max_retries=5)

    def _get_or_create_cli_client(on_success: action(router_client.Client) -> None, on_error: action(Exception) -> None):
        """Get existing CLI client or create a new one for conversion operations"""
        cli_client = conversion_cli_client
        if cli_client is not None:
            _log.debug("Reusing existing CLI client for conversion")
            on_success(cli_client)
        else:
            _log.info("Creating new CLI client for conversion")
            creds = _get_credentials()
            if creds is not None:
                username, password = creds
            else:
                on_error(Exception("No credentials available"))
                return

            # Determine device type based on platform
            device_type = None
            if device_platform == "cisco_iosxr":
                device_type = "cisco_iosxr"
            elif device_platform == "cisco_iosxe":
                device_type = "cisco_iosxe"
            elif device_platform == "junos":
                device_type = "juniper_junos"
            else:
                on_error(Exception("Unrecognized device platform: {device_platform}"))
                return

            # Create the client
            client = router_client.Client(
                auth=auth,
                address=ip_address,
                username=username,
                password=password,
                port=ssh_port,
                device_type=device_type,
                log_handler=log_handler
            )

            conversion_cli_client = client

            # Wait for connection
            def try_connect(attempt: int):
                if client.is_connected():
                    _log.info("CLI client created and stored for reuse")
                    on_success(client)
                elif attempt < 10:  # Retry for up to 5 seconds
                    _log.debug("CLI client not ready, retrying", {"attempt": attempt + 1})
                    after 0.5: try_connect(attempt + 1)
                else:
                    _log.error("CLI client failed to connect")
                    conversion_cli_client = None  # Clear the failed client
                    on_error(Exception("CLI client connection timeout"))

            after 0.1: try_connect(0)

    # IOS-XE cisco-ia namespace for sync operations
    CISCO_IA_NS = "http://cisco.com/yang/cisco-ia"

    def _iosxe_sync_from(callback: action(?Exception) -> None):
        """Force IOS-XE to sync CLI config to NETCONF datastore via cisco-ia:sync-from RPC"""
        _log.info("Triggering IOS-XE sync-from RPC")

        def on_client_success(client: netconf.Client):
            def on_rpc_done(client: netconf.Client, response: ?xml.Node, error: ?netconf.NetconfError):
                if error is not None:
                    _log.error("IOS-XE sync-from RPC failed", {"error": str(error)})
                    callback(Exception(f"sync-from RPC failed: {error}"))
                else:
                    _log.info("IOS-XE sync-from RPC completed successfully")
                    callback(None)

            # Build cisco-ia:sync-from RPC
            sync_from_node = xml.Node("sync-from", [(None, CISCO_IA_NS)], children=[])
            client.rpc(sync_from_node, on_rpc_done)

        def on_client_error(error: Exception):
            _log.error("Failed to get NETCONF client for sync-from", {"error": str(error)})
            callback(error)

        _get_or_create_netconf_client(on_client_success, on_client_error)

    def _iosxe_poll_sync_complete(callback: action(?Exception) -> None, max_attempts: int=30, poll_interval: float=1.0):
        """Poll cisco-ia:is-syncing until sync is complete"""
        _log.info("Polling IOS-XE is-syncing status")

        def poll(attempt: int):
            if attempt >= max_attempts:
                _log.error("IOS-XE sync polling timed out", {"max_attempts": max_attempts})
                callback(Exception(f"Sync polling timed out after {max_attempts} attempts"))
                return

            def on_client_success(client: netconf.Client):
                def on_rpc_done(client: netconf.Client, response: ?xml.Node, error: ?netconf.NetconfError):
                    if error is not None:
                        _log.error("IOS-XE is-syncing RPC failed", {"error": str(error), "attempt": attempt + 1})
                        callback(Exception(f"is-syncing RPC failed: {error}"))
                        return

                    # Parse response - look for <syncing> element with true/false value
                    is_syncing: bool = False
                    if response is not None:
                        for child in response.children:
                            if child.tag == "syncing":
                                ct = child.text
                                if ct is not None:
                                    is_syncing = ct.lower() == "true"
                                    _log.debug("is-syncing result", {"syncing": ct, "is_syncing": str(is_syncing)})
                                break

                    if is_syncing:
                        _log.debug("IOS-XE still syncing, polling again", {"attempt": attempt + 1})
                        after poll_interval: poll(attempt + 1)
                    else:
                        _log.info("IOS-XE sync complete", {"attempts": attempt + 1})
                        callback(None)

                # Build cisco-ia:is-syncing RPC
                is_syncing_node = xml.Node("is-syncing", [(None, CISCO_IA_NS)], children=[])
                client.rpc(is_syncing_node, on_rpc_done)

            def on_client_error(error: Exception):
                _log.error("Failed to get NETCONF client for is-syncing poll", {"error": str(error)})
                callback(error)

            _get_or_create_netconf_client(on_client_success, on_client_error)

        poll(0)

    def _iosxe_sync_and_get_config(module_set: str, callback: action(?(raw: xml.Node, gdata: yang.gdata.Node), ?Exception) -> None):
        """Full IOS-XE sync workflow: sync-from -> poll is-syncing -> get-config"""
        _log.info("Starting IOS-XE sync and config retrieval")

        def on_sync_from_done(error: ?Exception):
            if error is not None:
                _log.warning("sync-from failed, continuing with poll", {"error": str(error)})
            _iosxe_poll_sync_complete(on_poll_complete)

        def on_poll_complete(error: ?Exception):
            if error is not None:
                _log.warning("Sync poll failed, attempting config retrieval anyway", {"error": str(error)})
            _get_netconf_config_parsed(module_set, callback)

        _iosxe_sync_from(on_sync_from_done)



    def _cleanup_conversion_clients():
        """Clean up persistent clients at end of conversion"""
        _log.info("Cleaning up conversion clients")

        cnc = conversion_netconf_client
        if cnc is not None:
            try:
                cnc.close()
            except Exception as e:
                _log.warning("Error closing NETCONF client", {"error": str(e)})
            conversion_netconf_client = None

        ccc = conversion_cli_client
        if ccc is not None:
            try:
                ccc.disconnect()
            except Exception as e:
                _log.warning("Error closing CLI client", {"error": str(e)})
            conversion_cli_client = None

    def convert(request: ConvertRequest, result_callback: action(?(base_config: str, steps: list[(input: str, config: str, diff: str)]), ?Exception) -> None):
        """Process a conversion request on this device"""
        _log.info("DeviceInstance.convert called", {"device": container_id, "input_format": request.format, "output_format": request.target_format, "module_set": request.module_set, "steps": len(request.input)})
        _log.debug("Input steps", {"device": container_id, "input_steps": request.input})

        state = "busy"

        # Local variables for this conversion only
        base_gdata: ?yang.gdata.Node = None
        base_gdata_all: ?yang.gdata.Node = None
        base_xml: ?xml.Node = None
        latest_gdata_all: ?yang.gdata.Node = None

        # Variables to hold formatted base config
        base_config_formatted = ""

        # List to store formatted results for each step (for API response)
        steps_results: list[(input: str, config: str, diff: str)] = []

        # List to store gdata for each step (for rollback and diffs)
        steps_gdata: list[yang.gdata.Node] = []


        # Helper function to format gdata output based on target format
        def format_gdata_output(gdata: yang.gdata.Node, target_format: str) -> str:
            """Format parsed gdata to the requested output format"""
            if target_format == "json":
                return gdata.to_jsonstr()
            elif target_format == "acton-gdata":
                return gdata.prsrc()
            elif target_format == "acton-adata":
                compiled_schema, error = get_compiled_schema(request.module_set)
                if compiled_schema is not None:
                    return yang.data.pradata(compiled_schema, gdata, loose=True, self_name="dev")
                else:
                    _log.warning("No compiled schema for adata conversion, using gdata", {"error": compiled_schema})
                    return gdata.prsrc()
            elif target_format in ["netconf", "xml"]:
                return gdata.to_xmlstr(pretty=True)
            else:
                _log.warning("Unknown target format, using XML", {"target_format": target_format})
                return gdata.to_xmlstr(pretty=True)

        def on_base_config_retrieved(config_tuple: ?(raw: xml.Node, gdata: yang.gdata.Node), error: ?Exception):
            """Step 1: Process the retrieved base configuration"""
            if error is not None:
                _log.error("Failed to retrieve base configuration", {"error": str(error)})
                abort("Failed to retrieve base configuration: " + str(error))
                return

            if config_tuple is None:
                _log.error("No configuration tuple returned")
                abort("No configuration returned")
                return

            if config_tuple is not None:
                raw_xml: xml.Node = config_tuple.raw
                parsed_gdata: yang.gdata.Node = config_tuple.gdata

                _log.info("Base configuration retrieved and parsed successfully")

                # Store for later use
                base_xml = raw_xml  # Save raw XML node for rollback
                base_gdata = parsed_gdata  # Save parsed data for diff
                base_gdata_all_parsed = _parse_gdata(raw_xml, ALL_MODULE_SET, "base config")
                if base_gdata_all_parsed.gdata is None:
                    err_msg = base_gdata_all_parsed.error
                    abort(err_msg if err_msg is not None else "Failed to parse base config (full module-set)")
                    return
                base_gdata_all = base_gdata_all_parsed.gdata

                # Format base config for response
                if request.target_format == "cli":
                    # CLI needs special handling
                    _get_cli_config(on_base_cli_retrieved)
                else:
                    # Format gdata for response
                    base_config_formatted = format_gdata_output(parsed_gdata, request.target_format)
                    on_base_formatted()

        def on_base_cli_retrieved(cli_config: ?str, error: ?Exception):
            """Handle CLI format for base configuration"""
            if error is not None:
                _log.error("Failed to get CLI base config", {"error": str(error)})
                abort("Failed to get CLI base config: " + str(error))
                return
            if cli_config is None:
                _log.error("CLI config is None")
                abort("CLI config is None")
                return
            base_config_formatted = cli_config
            on_base_formatted()

        def on_base_formatted():
            """Step 2: Base config is formatted, now process input steps"""
            _log.info("Base configuration formatted, starting sequential input processing")

            # Start processing first step
            process_next_step(0)

        def process_next_step(current_step_index: int):
            """Process the next configuration step"""
            if current_step_index >= len(request.input):
                # All steps completed, now rollback and finalize
                _log.info("All steps completed, starting rollback")
                on_all_steps_complete()
                return

            _log.info("Processing step", {"step": current_step_index + 1, "of": len(request.input)})

            # For IOS XE, clear the archive log before each step because we rely
            # on "show archive log ..." to compute the CLI diff. This works for
            # both CLI and NETCONF inputs
            if device_platform == "cisco_iosxe":
                def on_step_archive_cleared(err: ?Exception):
                    if err is not None:
                        _log.error("Failed to clear archive log before step", {"step": current_step_index + 1, "error": str(err)})
                        abort(f"Failed to clear archive log before step {current_step_index + 1}: {str(err)}")
                    else:
                        _log.debug("Archive log cleared before step", {"step": current_step_index + 1})
                        # Apply current step's configuration
                        current_input = request.input[current_step_index]
                        _handle_input(request.format, current_input, lambda error: on_step_input_applied(current_step_index, error))
                _clear_iosxe_archive_log(on_step_archive_cleared)
            else:
                # Apply current step's configuration
                current_input = request.input[current_step_index]
                _handle_input(request.format, current_input, lambda error: on_step_input_applied(current_step_index, error))

        def on_step_input_applied(current_step_index: int, error: ?Exception):
            """Called after a step's input has been applied"""
            if error is not None:
                _log.error("Step input application failed", {"step": current_step_index + 1, "error": str(error)})
                abort(f"Failed at step {current_step_index + 1}: {str(error)}")
                return

            _log.info("Step input applied successfully, retrieving configuration", {"step": current_step_index + 1})

            # IOS-XE has a delay between CLI commit and NETCONF visibility.
            # Use sync-from RPC and poll is-syncing to ensure consistency.
            if device_platform == "cisco_iosxe" and request.format == "cli":
                _iosxe_sync_and_get_config(request.module_set, lambda config_tuple, error: on_step_config_retrieved(current_step_index, config_tuple, error))
            else:
                _get_netconf_config_parsed(request.module_set, lambda config_tuple, error: on_step_config_retrieved(current_step_index, config_tuple, error))

        def on_step_config_retrieved(current_step_index: int, config_tuple: ?(raw: xml.Node, gdata: yang.gdata.Node), error: ?Exception):
            """Process the configuration after a step"""
            if error is not None:
                _log.error("Failed to retrieve step configuration", {"step": current_step_index + 1, "error": str(error)})
                abort(f"Failed to retrieve configuration at step {current_step_index + 1}: {str(error)}")
                return

            if config_tuple is not None:
                step_raw_xml: xml.Node = config_tuple.raw
                step_gdata: yang.gdata.Node = config_tuple.gdata

                _log.info("Step configuration retrieved", {"step": current_step_index + 1})

                # Store gdata for this step
                steps_gdata.append(step_gdata)
                step_gdata_all_parsed = _parse_gdata(step_raw_xml, ALL_MODULE_SET, f"step {current_step_index + 1} config")
                if step_gdata_all_parsed.gdata is None:
                    err_msg = step_gdata_all_parsed.error
                    abort(err_msg if err_msg is not None else f"Failed to parse step {current_step_index + 1} config (full module-set)")
                    return
                latest_gdata_all = step_gdata_all_parsed.gdata

                # Format config for this step
                if request.target_format == "cli":
                    _get_cli_config(lambda cli_config, error: on_step_cli_retrieved(current_step_index, cli_config, error))
                else:
                    step_config_formatted = format_gdata_output(step_gdata, request.target_format)
                    on_step_formatted(current_step_index, step_config_formatted)
            else:
                _log.error("No configuration returned for step", {"step": current_step_index + 1})
                abort(f"No configuration returned for step {current_step_index + 1}")

        def on_step_cli_retrieved(current_step_index: int, cli_config: ?str, error: ?Exception):
            """Handle CLI format for step configuration"""
            if error is not None:
                _log.error("Failed to get CLI config for step", {"step": current_step_index + 1, "error": str(error)})
                abort(f"Failed to get CLI config for step {current_step_index + 1}: {str(error)}")
                return
            elif cli_config is not None:
                on_step_formatted(current_step_index, cli_config)
                return
            else:
                _log.error("CLI config is None for step", {"step": current_step_index + 1})
                abort(f"CLI config is None for step {current_step_index + 1}")
                return

        def on_step_formatted(current_step_index: int, step_config: str):
            """Step config formatted, compute diff and store results"""
            _log.info("Computing diff for step", {"step": current_step_index + 1})

            # Define callback with closure over step_config and index
            def on_step_diff_computed_with_config(diff_text: ?str, error: ?Exception):
                on_step_diff_computed(current_step_index, step_config, diff_text, error)

            # Compute incremental diff
            if request.target_format == "cli":
                # For CLI, we'll use the CLI diff command
                _get_cli_diff(on_step_diff_computed_with_config)
            else:
                # Compute gdata diff
                current_gdata = steps_gdata[current_step_index]
                if current_step_index == 0:
                    # First step - diff from base
                    diff_text = _compute_gdata_diff(base_gdata, current_gdata, request.target_format, request.module_set) if base_gdata is not None else ""
                else:
                    # Subsequent steps - diff from previous step
                    previous_step_gdata = steps_gdata[current_step_index - 1]
                    diff_text = _compute_gdata_diff(previous_step_gdata, current_gdata, request.target_format, request.module_set)
                on_step_diff_computed_with_config(diff_text, None)

        def on_step_diff_computed(current_step_index: int, step_config: str, diff_text: ?str, error: ?Exception):
            """Store step results and move to next step"""
            computed_diff = diff_text if diff_text is not None else ""

            # Store this step's results as a named tuple
            step_result = (
                input=request.input[current_step_index],
                config=step_config,
                diff=computed_diff
            )
            steps_results.append(step_result)

            # Move to next step
            process_next_step(current_step_index + 1)

        def verify_restored_config(expected_base_gdata: yang.gdata.Node, callback: action(?Exception) -> None):
            """Verify device configuration matches base after rollback (full module-set)"""
            _log.info("Verifying device configuration matches base state after rollback", {"module_set": ALL_MODULE_SET})

            def on_verify_config_retrieved(config_tuple: ?(raw: xml.Node, gdata: yang.gdata.Node), error: ?Exception):
                if error is not None:
                    _log.error("Failed to retrieve config for rollback verification", {"error": str(error)})
                    callback(Exception("Failed to verify rollback state: " + str(error)))
                    return

                if config_tuple is not None:
                    current_gdata: yang.gdata.Node = config_tuple.gdata
                    diff_result: ?yang.gdata.Node = yang.gdata.diff(expected_base_gdata, current_gdata)
                    if diff_result is not None:
                        diff_preview = diff_result.prsrc()
                        _log.error("Rollback verification failed: device differs from base state", {"diff_preview": diff_preview[:1000]})
                        callback(Exception("Rollback verification failed: device configuration does not match base state"))
                    else:
                        _log.info("Rollback verification succeeded: device matches base state")
                        callback(None)
                else:
                    _log.error("No configuration returned for rollback verification")
                    callback(Exception("Failed to verify rollback state: no configuration returned"))

            _get_netconf_config_parsed(ALL_MODULE_SET, on_verify_config_retrieved)

        def on_all_steps_complete():
            """All steps completed, perform rollback"""
            _log.info("All configuration steps completed, starting rollback")

            # Get final gdata (last step's gdata) for rollback
            final_gdata = steps_gdata[-1] if len(steps_gdata) > 0 else None
            final_gdata_all = latest_gdata_all

            # Start rollback process
            if base_xml is not None and base_gdata is not None and final_gdata is not None:
                if base_gdata_all is not None and final_gdata_all is not None:
                    _log.info("Starting automatic rollback to clean device state using NETCONF", {"module_set": ALL_MODULE_SET})
                    _rollback_to_config(base_xml, base_gdata_all, final_gdata_all, on_rollback_complete)
                else:
                    _log.error("Full module-set gdata missing for rollback; falling back to request module-set", {"base_gdata_all": base_gdata_all is not None, "final_gdata_all": final_gdata_all is not None})
                    _rollback_to_config(base_xml, base_gdata, final_gdata, on_rollback_complete)
            else:
                _log.error("Missing data for rollback")
                on_rollback_complete(Exception("Missing data for rollback"))


        def on_rollback_complete(rollback_error: ?Exception):
            """Rollback complete, verify and finish the conversion"""
            if rollback_error is not None:
                _log.error("Rollback failed after successful conversion", {"error": str(rollback_error)})
                state = "error"
                finish(Exception("Rollback failed after successful conversion: " + str(rollback_error)), None)
                return

            if base_gdata_all is not None:
                verify_restored_config(base_gdata_all, on_success_rollback_verified)
            else:
                state = "error"
                finish(Exception("Missing base configuration for rollback verification"), None)

        def on_success_rollback_verified(verification_error: ?Exception):
            """Handle rollback verification for successful conversion"""
            if verification_error is not None:
                _log.error("Rollback verification failed after successful conversion", {"error": str(verification_error)})
                state = "error"
                finish(verification_error, None)
                return

            _log.info("Device successfully rolled back to clean state")
            complete()

        def complete():
            """Successfully complete the conversion"""
            # Return base config and steps as a named tuple
            result = (
                base_config=base_config_formatted,
                steps=steps_results
            )
            finish(None, result)

        def abort(error: str):
            """Abort the conversion due to error and rollback to initial state"""
            _log.error("Conversion aborted, attempting rollback", {"error": error})

            # Only rollback if we have made changes (base_xml exists means we got past initial config)
            if base_xml is not None and base_gdata is not None and len(steps_gdata) > 0:
                # We have applied at least one step, need to rollback
                current_gdata = steps_gdata[-1]
                _log.info("Rolling back to initial state after error")
                if base_gdata_all is not None and latest_gdata_all is not None:
                    _rollback_to_config(base_xml, base_gdata_all, latest_gdata_all, lambda rollback_error: on_abort_rollback_complete(error, rollback_error))
                else:
                    _log.error("Full module-set gdata missing for rollback after abort; falling back to request module-set", {"base_gdata_all": base_gdata_all is not None, "current_gdata_all": latest_gdata_all is not None})
                    _rollback_to_config(base_xml, base_gdata, current_gdata, lambda rollback_error: on_abort_rollback_complete(error, rollback_error))
            else:
                # Either no base config (failed early) or no steps applied - nothing to rollback
                _log.info("No rollback needed - no changes were applied")
                finish(Exception(error), None)

        def on_abort_rollback_complete(original_error: str, rollback_error: ?Exception):
            """Handle rollback completion after abort"""
            if rollback_error is not None:
                _log.error("Failed to rollback after abort", {"rollback_error": str(rollback_error)})
                state = "error"
                finish(Exception(original_error + "; rollback failed: " + str(rollback_error)), None)
                return

            if base_gdata_all is not None:
                verify_restored_config(base_gdata_all, lambda verification_error: on_abort_rollback_verified(original_error, verification_error))
            else:
                state = "error"
                finish(Exception(original_error + "; missing base configuration for rollback verification"), None)

        def on_abort_rollback_verified(original_error: str, verification_error: ?Exception):
            """Handle rollback verification after abort"""
            if verification_error is not None:
                _log.error("Rollback verification failed after abort", {"error": str(verification_error)})
                state = "error"
                finish(Exception(original_error + "; " + str(verification_error)), None)
                return

            _log.info("Successfully rolled back to initial state after abort")
            # Always finish with the original error that caused the abort
            finish(Exception(original_error), None)

        def finish(error: ?Exception, result):
            """Final cleanup and callback"""
            # Reset state unless an irrecoverable failure has already marked this device as error
            if state != "error":
                state = "ready"

            _cleanup_conversion_clients()

            # Call the result callback
            if error is not None:
                result_callback(None, error)
            elif result is not None:
                result_callback(result, None)
            else:
                result_callback(None, Exception("Unknown error"))

        # Start the conversion process
        _log.info("Getting base configuration")

        # For IOS XE, clear the archive log at the beginning of conversion for clean state
        if device_platform == "cisco_iosxe":
            def on_archive_clear_done(err: ?Exception):
                if err is None:
                    _get_netconf_config_parsed(request.module_set, on_base_config_retrieved)
                else:
                    abort("Failed to clear archive log: " + str(err))
            _clear_iosxe_archive_log(on_archive_clear_done)
        else:
            _get_netconf_config_parsed(request.module_set, on_base_config_retrieved)

    def _handle_input(input_format: str, input_data: str, callback: action(?Exception) -> None):
        """Apply input data using the appropriate input handler"""
        _log.info("Handling input format", {"input_format": input_format})

        if input_format == "netconf":
            _netconf_input(input_data, callback)
        elif input_format == "cli":
            _cli_input(input_data, callback)
        elif input_format == "restconf":
            # TODO: Implement RESTCONF input handler
            _log.error("RESTCONF input handler not yet implemented")
            callback(Exception("RESTCONF input handler not implemented"))
        else:
            _log.error("Unsupported input format", {"input_format": input_format})
            callback(Exception(f"Unsupported input format: {input_format}"))

    def _netconf_input(input_data: str, callback: action(?Exception) -> None):
        """Apply configuration via NETCONF edit-config"""
        _log.info("NETCONF input handler: applying configuration")

        def on_client_success(client: netconf.Client):
            _log.info("NETCONF client connected successfully")

            def on_edit_config_done(client: netconf.Client, error: ?netconf.NetconfError):
                _log.debug("Edit-config response received")
                if error is not None:
                    _log.error("Edit-config failed with NETCONF error", {"error": error})
                    callback(Exception(f"NETCONF edit-config error: {error}"))
                else:
                    _log.info("Edit-config completed successfully")

                    # Now commit the candidate configuration
                    _log.debug("Sending commit request")
                    client.commit(on_commit_done)

            def on_commit_done(client: netconf.Client, error: ?netconf.NetconfError):
                _log.debug("Commit response received")
                if error is not None:
                    _log.error("Commit failed with NETCONF error", {"error": error})
                    callback(Exception(f"NETCONF commit error: {error}"))
                else:
                    _log.info("Commit completed successfully")
                    callback(None)

            # Apply the input configuration
            _log.debug("Sending edit-config with input", {"input_data": input_data})
            input_xml = xml.decode("<data>{input_data}</data>")
            _edit_config_with_retry(client, input_xml.children, on_edit_config_done if has_candidate() else on_commit_done, target_datastore())

        def on_client_error(error: Exception):
            _log.error("Failed to get NETCONF client", {"error": str(error)})
            callback(error)

        _get_or_create_netconf_client(on_client_success, on_client_error)

    def _cli_input(input_data: str, callback: action(?Exception) -> None):
        """Apply CLI configuration via router_client"""
        _log.info("CLI input handler: applying CLI configuration")

        # Parse CLI commands from input data (split by newlines)
        cli_commands = []
        for line in input_data.split("\n"):
            line = line.strip()
            if line != "" and not line.startswith("#"):  # Skip empty lines and comments
                cli_commands.append(line)

        if not cli_commands:
            callback(Exception("No valid CLI commands found in input"))
            return

        _log.debug("Parsed CLI commands", {"commands": cli_commands, "count": len(cli_commands)})

        def on_client_success(client: router_client.Client):

            def on_success(response: str):
                _log.info("CLI configuration applied successfully")
                _log.debug("CLI success response", {"response": response})
                callback(None)

            def on_error(err: Exception, response: str):
                _log.error("CLI configuration failed", {"error": str(err), "response": response})
                callback(Exception("CLI configuration error: " + str(err)))

            _log.debug("CLI client connected, sending configuration commands")
            client.configure_and_commit(on_success, on_error, cli_commands)

        def on_client_error(error: Exception):
            _log.error("Failed to get CLI client", {"error": str(error)})
            callback(error)

        _get_or_create_cli_client(on_client_success, on_client_error)

    def _get_cli_config(callback: action(?str, ?Exception) -> None):
        """Utility function to get CLI config without managing conversion state"""
        _log.info("CLI config utility: retrieving configuration")

        def on_client_success(client: router_client.Client):

            def on_cmd_complete(err: ?Exception, response: ?str):
                if err is not None:
                    _log.error("CLI config retrieval failed", {"error": str(err)})
                    callback(None, Exception("CLI config error: " + str(err)))
                elif response is not None:
                    _log.info("CLI config retrieved successfully")
                    _log.debug("CLI config response", {"response_length": len(response)})
                    callback(response, None)
                else:
                    _log.error("CLI config failed - received None response")
                    callback(None, Exception("CLI config failed"))

            _log.debug("CLI utility client connected, sending show config command")
            client.cmd(on_cmd_complete, "show configuration")

        def on_client_error(error: Exception):
            _log.error("Failed to get CLI client", {"error": str(error)})
            callback(None, error)

        _get_or_create_cli_client(on_client_success, on_client_error)

    def _parse_gdata(raw_xml: xml.Node, module_set: str, context: str) -> (gdata: ?yang.gdata.Node, error: ?str):
        """Parse XML into gdata with the specified module-set"""
        compiled_schema, serror = get_compiled_schema(module_set)
        if compiled_schema is not None:
            try:
                _log.debug("Parsing raw XML with compiled schemas", {"module_set": module_set, "context": context})
                parsed_gdata = yang.xml.from_xml(compiled_schema, raw_xml, loose=True)
                return (gdata=parsed_gdata, error=None)
            except Exception as e:
                _log.error("Failed to parse raw XML with compiled schemas", {"module_set": module_set, "context": context, "error": str(e)})
                return (gdata=None, error="Parse failed: " + str(e))

        _log.error("No compiled schema for parsing", {"module_set": module_set, "context": context, "error": serror})
        return (gdata=None, error="No compiled schema available")

    def _get_netconf_config_parsed(module_set: str, result_callback: action(?(raw: xml.Node, gdata: yang.gdata.Node), ?Exception) -> None):
        """Get NETCONF config and parse it with schemas

        Returns a tuple of (raw_xml, parsed_gdata) to the callback on success, or None with an exception on failure.
        The tuple components are guaranteed to be non-None when the tuple itself is returned.
        """
        _log.info("Getting NETCONF config with parsing")

        def on_client_success(client: netconf.Client):
            _log.info("NETCONF client connected successfully")

            def on_get_config_done(client: netconf.Client, response: ?xml.Node, error: ?netconf.NetconfError):
                _log.debug("Get-config response received")
                if error is not None:
                    _log.error("Get-config failed with NETCONF error", {"error": error})
                    result_callback(None, Exception("Get-config failed with NETCONF error: " + str(error)))
                elif response is not None:
                    # Extract the <data> element from the RPC reply
                    config_xml: ?xml.Node = None
                    for child in response.children:
                        if child.tag == "data":
                            config_xml = child
                            break

                    if config_xml is not None:
                        _log.debug("Got raw XML", {"length": len(xml.encode(config_xml))})

                        # Parse with schemas - this is required for conversion
                        parsed = _parse_gdata(config_xml, module_set, "netconf get-config")
                        parsed_gdata = parsed.gdata
                        if parsed_gdata is not None:
                            _log.info("Successfully parsed to gdata")
                            result_callback((raw=config_xml, gdata=parsed_gdata), None)
                        else:
                            err_msg = parsed.error
                            result_callback(None, Exception(err_msg if err_msg is not None else "Parse failed"))
                    else:
                        _log.error("No data element in get-config response")
                        result_callback(None, Exception("No data element in get-config response"))
                else:
                    _log.error("Get-config failed - received None response")
                    result_callback(None, Exception("Get-config failed - received None response"))

            client.get_config(on_get_config_done)

        def on_client_error(error: Exception):
            _log.error("Failed to get NETCONF client", {"error": str(error)})
            result_callback(None, error)

        _get_or_create_netconf_client(on_client_success, on_client_error)

    def _cli_output(result_callback: action(?str, ?Exception) -> None):
        """Retrieve configuration via CLI commands"""
        _log.info("CLI output handler: retrieving configuration")

        def on_client_success(client: router_client.Client):
            _log.debug("CLI client ready for show configuration")

            def on_cmd_complete(err: ?Exception, response: ?str):
                if err is not None:
                    _log.error("CLI show configuration failed", {"error": str(err)})
                    state = "ready"
                    result_callback(None, Exception("CLI show configuration error: " + str(err)))
                elif response is not None:
                    _log.info("CLI show configuration completed successfully")
                    _log.debug("CLI response", {"response_length": len(response)})
                    state = "ready"
                    result_callback(response, None)
                else:
                    _log.error("CLI show configuration failed - received None response")
                    state = "ready"
                    result_callback(None, Exception("CLI show configuration failed"))

            _log.debug("CLI client connected, sending show configuration command")
            client.cmd(on_cmd_complete, "show configuration")

        def on_client_error(error: Exception):
            _log.error("Failed to get CLI client", {"error": str(error)})
            state = "ready"
            result_callback(None, error)

        _get_or_create_cli_client(on_client_success, on_client_error)

    def _get_cli_diff(result_callback: action(?str, ?Exception) -> None):
        """Get CLI diff using 'show configuration | compare rollback 1'"""
        _log.info("CLI diff handler: getting configuration differences")

        def on_client_success(client: router_client.Client):
            _log.debug("CLI client ready for diff command")

            def on_cmd_complete(err: ?Exception, response: ?str):
                if err is not None:
                    _log.error("CLI diff command failed", {"error": str(err)})
                    result_callback(None, Exception("CLI diff error: " + str(err)))
                elif response is not None:
                    _log.info("CLI diff retrieved successfully")
                    _log.debug("CLI diff response", {"response_length": len(response)})
                    result_callback(response, None)
                else:
                    _log.error("CLI diff failed - received None response")
                    result_callback(None, Exception("CLI diff failed"))

            # Determine diff command based on platform
            diff_command = None
            if device_platform == "cisco_iosxr":
                diff_command = "show configuration commit changes last 1"
            elif device_platform == "cisco_iosxe":
                diff_command = "show archive log config all provisioning"
            elif device_platform == "junos":
                diff_command = "show configuration | compare rollback 1"
            else:
                result_callback(None, Exception("Unrecognized device platform: {device_platform}"))
                return

            if diff_command is not None:
                _log.debug("CLI client connected, sending diff command", {"command": diff_command})
                client.cmd(on_cmd_complete, diff_command)

        def on_client_error(error: Exception):
            _log.error("Failed to get CLI client", {"error": str(error)})
            result_callback(None, error)

        _get_or_create_cli_client(on_client_success, on_client_error)

    def _compute_gdata_diff(base_gdata: yang.gdata.Node, final_gdata: yang.gdata.Node, target_format: str, module_set: str) -> str:
        """Compute diff between base and final gdata configs"""
        try:
            # Use yang.gdata.diff for semantic diff
            diff_result = yang.gdata.diff(base_gdata, final_gdata)

            if diff_result is not None:
                # Convert diff to appropriate format based on target_format
                if target_format == "json":
                    return diff_result.to_jsonstr()
                elif target_format == "acton-gdata":
                    return diff_result.prsrc()
                elif target_format == "acton-adata":
                    # Convert diff to adata format if schema is available
                    compiled_schema, error = get_compiled_schema(module_set)
                    if compiled_schema is not None:
                        return yang.data.pradata(compiled_schema, diff_result, loose=True, self_name="dev")
                    else:
                        _log.warning("No compiled schema for adata diff conversion, using prsrc", {"error": error})
                        return diff_result.prsrc()
                elif target_format in ["netconf", "xml"]:
                    # For XML formats, return the diff as XML string
                    return diff_result.to_xmlstr()
                else:
                    # Default to prsrc format for unknown formats
                    _log.warning("Unknown target format for diff, using prsrc", {"target_format": target_format})
                    return diff_result.prsrc()
            else:
                _log.info("No differences found between base and final configs")
                return "No configuration changes"
        except Exception as e:
            _log.error("Failed to compute gdata diff", {"error": str(e)})
            return ""

    def apply_netconf_config(config: str, config_name: str):
        """Generic method to apply NETCONF configuration to device"""
        _log.info("Applying NETCONF configuration", {"device": container_id, "config": config_name})

        # Get credentials
        creds = _get_credentials()
        if creds is not None:
            username, password = creds
        else:
            _log.error("No credentials available for configuration", {"config": config_name})
            return

        def on_connect_success(client: netconf.Client):
            _log.debug("Connected to device for configuration", {"config": config_name})

            def on_edit_config_done(c: netconf.Client, error: ?netconf.NetconfError):
                if error is not None:
                    _log.error("Failed to apply configuration", {"error": error.error_message, "config": config_name})
                    c.close()
                else:
                    _log.info("Successfully applied configuration", {"config": config_name})
                    # Commit the configuration
                    c.commit(on_commit_done)

            def on_commit_done(c: netconf.Client, error: ?netconf.NetconfError):
                if error is not None:
                    _log.error("Failed to commit configuration", {"error": error.error_message, "config": config_name})
                else:
                    _log.info("Configuration committed", {"config": config_name})
                c.close()

            # Parse and apply the config XML
            try:
                config_xml =  xml.decode("<data>{config}</data>")
                _edit_config_with_retry(client, config_xml.children, on_edit_config_done if has_candidate() else on_commit_done, target_datastore())
            except Exception as e:
                _log.error("Failed to parse configuration", {"error": str(e), "config": config_name})
                client.close()

        def on_connect_failure(error: Exception):
            _log.error("NETCONF connection failed for configuration after retries", {"error": str(error), "config": config_name})

        # Create NETCONF client for configuration (unlimited retries for initialization)
        _log.info("Creating NETCONF client for configuration", {"config": config_name})
        create_netconf_client_with_retry(username, password, on_connect_success, on_connect_failure)

    def configure_rfc_compliance():
        """Configure the device for RFC/YANG compliant NETCONF operation (Juniper-specific)"""
        # Configuration to enable RFC-compliant and YANG-compliant modes
        config_xml = """
        <configuration>
            <system>
                <services>
                    <netconf>
                        <rfc-compliant/>
                        <yang-compliant/>
                    </netconf>
                </services>
            </system>
        </configuration>
        """
        apply_netconf_config(config_xml, "RFC/YANG compliance")

    def configure_iosxe_archive_ssh():
        """Configure archive on IOS XE device for configuration tracking"""
        config = """<native xmlns="http://cisco.com/ns/yang/Cisco-IOS-XE-native">
    <archive>
        <log>
            <config>
                <logging>
                    <enable/>
                </logging>
            </config>
        </log>
        <path>bootflash:archive</path>
    </archive>
    <ip>
        <ssh>
            <server>
                <peruser>
                    <session>
                        <limit>16</limit>
                    </session>
                </peruser>
            </server>
            <maxstartups>128</maxstartups>
        </ssh>
    </ip>
</native>"""

        apply_netconf_config(config, "IOS XE archive, SSH limits")

    def initialize_schemas(module_sets):
        """Initialize schemas by downloading them from the device and compiling them"""
        _log.info("Initializing YANG schemas for device", {"device": container_id})

        # Get credentials
        creds = _get_credentials()
        if creds is not None:
            username, password = creds
        else:
            _log.error("No credentials available for schema initialization")
            state = "error"
            return

        def on_connect_success(client: netconf.Client):
            _log.info("Connected to device for schema initialization")
            sw = time.Stopwatch()
            schema_getter: ?netconf.SchemaGetter = None

            def on_list_schemas(c: netconf.Client, schemas: list[(identifier: str, namespace: str, version: str, format: str)], error: ?netconf.NetconfError):
                if error is not None:
                    _log.error("Error: Failed to list schemas: {error}")
                    state = "error"
                    return

                # Filter only YANG schemas because we only compile YANG
                for s in schemas:
                    if s.format != "yang":
                        continue
                    # Skip known broken models:
                    # - junos-rpc: all RPC modules use an undefined grouping?!
                    # - tailf-rollback: Unable to get child yang-patch-status from non-inner node
                    if s.identifier.startswith("junos-rpc"):
                        _log.debug("Skipping {s.identifier}: undefined grouping common-forwarding")
                        continue
                    elif s.identifier == "tailf-rollback" or s.identifier.startswith("cicso-xe-openconfig"):
                        _log.debug("Skipping {s.identifier}: Cisco IOS XE ")
                        continue
                    sid = _SchemaId(s.identifier, s.version, s.format)

                    if len(module_sets) > 0:
                        # Use module set filtering
                        for module_set in module_sets:
                            if schema_filter.should_include_module(s.identifier, [module_set]):
                                expanded_module_sets.setdefault(module_set, set())
                                expanded_module_sets[module_set].add(sid)

                    # Also "create" the wildcard (all module-set)
                    expanded_module_sets.setdefault(ALL_MODULE_SET, set())
                    expanded_module_sets[ALL_MODULE_SET].add(sid)

                schemas_to_download = set()
                for mss in expanded_module_sets.values():
                    schemas_to_download.update(mss)

                if len(schemas_to_download) == 0:
                    _log.error("No schemas available for download")
                    state = "error"
                    return

                print("Found {len(schemas_to_download)} schemas to download", {"duration": sw.elapsed().to_float()})
                sw.reset()
                schema_getter = netconf.SchemaGetter(c)
                schema_getter.download(on_schema_download, on_schemas_complete, [std.to_named_tuple() for std in schemas_to_download])

            # Callback for each schema download
            def on_schema_download(sg, current_index: int, total_schemas: int, schema: (identifier: str, version: ?str, format: ?str), schema_data: ?str, error: ?netconf.NetconfError):
                if schema_getter is not None and sg is not schema_getter:
                    _log.debug("Ingoring callback from old SchemaGetter")
                    return
                if error is not None:
                    _log.error("Error downloading", {"identifier": schema.identifier, "index": current_index, "total": total_schemas, "error": error.error_message})
                elif schema_data is not None:
                    _log.debug("Downloaded schema", {"identifier": schema.identifier, "index": current_index, "total": total_schemas, "data": schema_data[:20]})
                    schema_dict[_SchemaId(schema.identifier, schema.version, schema.format)] = schema_data
                else:
                    _log.warning("Empty schema data", {"identifier": schema.identifier, "index": current_index, "total": total_schemas})

            # Callback when all schemas are complete
            def on_schemas_complete(sg, error: ?netconf.NetconfError):
                if schema_getter is not None and sg is not schema_getter:
                    _log.debug("Ingoring callback from old SchemaGetter")
                    return
                if error is not None:
                    _log.error("Error during schema download", {"error": error.error_message})
                    # Continue anyway - device can work without schemas

                _log.info("All schemas downloaded", {"count": len(schema_dict), "duration": sw.elapsed().to_float()})

                deleted = set(compiled_schemas.keys()) - set(expanded_module_sets.keys())
                for d in deleted:
                    del compiled_schemas[d]

                # Compile the schemas
                for name, modules in expanded_module_sets.items():
                    _log.debug("Compiling YANG schemas", {"module-set": name})
                    compiled_schemas.setdefault(name, None)
                    yangs = []
                    for sid in modules:
                        y = schema_dict.get_def(sid, "")
                        if y != "":
                            yangs.append(y)
                    schema_registry.add_schema(yangs, lambda d, h, e: on_compile(name, d, h, e))

                # Close the NETCONF connection
                client.close()

                # Set state to ready immediately so device can handle requests (basic, ones that do not require schema)
                # Schema compilation will happen in background
                state = "ready"
                _log.info("Device ready for requests, schema initialization continuing in background", {"device": container_id})

            # Callback when a module-set schema is compiled by SchemaRegistry
            def on_compile(name: str, duration: time.Duration, hash: ?u64, error: ?Exception):
                if error is not None:
                    compiled_schemas[name] = None
                    compiled_schemas_errors[name] = str(error)
                    _log.error("Failed to compile schemas", {"module-set": name, "error": str(error), "duration": duration.to_float()})
                elif hash is not None:
                    compiled_schemas[name] = hash
                    _log.info("Successfully compiled YANG schemas", {"module-set": name, "duration": duration.to_float()})


            client.list_schemas(on_list_schemas)

        def on_connect_failure(error: Exception):
            _log.error("Failed to connect for schema initialization after retries", {"error": str(error)})
            state = "error"

        # Create NETCONF client for schema initialization
        _log.info("Creating NETCONF client for schema initialization", {"host": ip_address, "port": netconf_port})
        create_netconf_client_with_retry(username, password, on_connect_success, on_connect_failure)


actor DeviceManager(config: SystemConfig, container_mgr: ContainerManager, auth: WorldCap, log_handler: logging.Handler):
    """Manages device lifecycle and state transitions"""
    var instances = []  # DeviceInstance actors
    var pending_requests = []  # Requests waiting for a device
    var next_instance_id = 1
    var schema_registry = SchemaRegistry(file.FileCap(auth))

    # Set up logging
    logh = logging.Handler("DeviceManager")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    def count_instances(platform_name: str, state: ?str = None) -> int:
        """Count instances for a platform, optionally filtered by state"""
        count = 0
        for device in instances:
            device_info = device.get_info()
            device_platform = device_info.get("platform_name")
            if isinstance(device_platform, str) and device_platform == platform_name:
                if state is None:
                    count += 1
                else:
                    device_state = device_info.get("state")
                    if isinstance(device_state, str) and device_state == state:
                        count += 1
        return count

    def initialize_static_instances(platform: PlatformConfig):
        """Initialize static instances for a platform"""
        for spec in platform.instances:
            device = DeviceInstance(
                auth=auth,
                log_handler=log_handler,
                platform_name=platform.name,
                platform=platform.platform,
                schema_registry=schema_registry,
                container_id=spec.id,
                ip_address=spec.host,
                netconf_port=spec.netconf_port,
                ssh_port=spec.ssh_port,
                instance_spec=spec
            )

            # For Juniper platforms, configure RFC compliance first
            if platform.platform == "junos":
                device.configure_rfc_compliance()

            # For Cisco IOS XE platforms, configure archive, SSH limits
            if platform.platform == "cisco_iosxe":
                device.configure_iosxe_archive_ssh()

            # Initialize schemas on device startup
            device.initialize_schemas(platform.module_sets)
            instances.append(device)

    def get_device_for_request(platform_name: str) -> ?DeviceInstance:
        """Get or create a device for a request"""
        # Debug logging
        _log.debug("Looking for device", {"requested_platform": platform_name, "total_instances": len(instances)})

        # Find a ready device for the specified platform
        for i in range(len(instances)):
            device = instances[i]
            device_info = device.get_info()
            info_platform = device_info.get("platform_name")
            device_state = device_info.get("state")
            _log.debug("Checking device", {"index": i, "platform": str(info_platform), "state": device_state})
            if isinstance(device_state, str) and device_state == "ready" and isinstance(info_platform, str) and info_platform == platform_name:
                _log.info("Found matching device", {"platform": platform_name, "index": i})
                return device
        _log.warning("No matching device found", {"platform": platform_name})
        return None

    def start_device(platform: PlatformConfig) -> ?DeviceInstance:
        """Start a new device instance (only for dynamically managed platforms)"""
        if platform.uses_static_instances():
            return None

        instance_id = str(next_instance_id)
        next_instance_id += 1

        # Create a placeholder device in starting state
        device = DeviceInstance(
            auth=auth,
            log_handler=log_handler,
            platform_name="dynamic-platform",  # Hardcoded for now
            platform="dynamic",  # Hardcoded for now
            schema_registry=schema_registry,
            container_id=f"starting-{instance_id}",
            ip_address="pending",
            netconf_port=830,  # Use default for now
            ssh_port=22  # Use default for now
        )
        device.set_state("starting")
        instances.append(device)

        return device

    def initialize_min_instances():
        """Initialize specified instances and start minimum number of container instances for each platform"""
        for platform in config.platforms:
            # First, initialize any static instances
            initialize_static_instances(platform)

            # Then start minimum container instances if needed
            if not platform.uses_static_instances() and platform.min_instances > 0:
                current_count = count_instances(platform.name)
                to_start = platform.min_instances - current_count
                for i in range(to_start):
                    start_device(platform)

    def get_instance_info() -> list[dict[str, ?value]]:
        """Get instance info for API responses"""
        # Dynamically collect info from all device instances
        current_info = []
        for device in instances:
            current_info.append(device.get_info())
        return current_info

    def get_config() -> SystemConfig:
        """Get system configuration"""
        return config


class InstanceSpec(object):
    """Specification for a static instance (physical device, VM, or pre-existing container)"""
    def __init__(self, id: str, host: str, netconf_port: int = 830,
                 ssh_port: int = 22, restconf_port: int = 443, username: ?str = None, password: ?str = None,
                 private_key_path: ?str = None, description: ?str = None):
        self.id = id
        self.host = host  # IP address or hostname
        self.netconf_port = netconf_port
        self.ssh_port = ssh_port
        self.restconf_port = restconf_port
        self.username = username
        self.password = password
        self.private_key_path = private_key_path
        self.description = description

class PlatformConfig(object):
    name: str
    platform: str
    container_image: ?str
    min_instances: int
    max_instances: int
    startup_time_seconds: int
    idle_timeout_seconds: int
    netconf_port: int
    ssh_port: int
    restconf_port: int
    module_sets: list[str]
    instances: list[InstanceSpec]
    active_instances: int
    available_instances: int

    def __init__(self, name: str, platform: str, container_image: ?str = None,
                 min_instances: int = 0, max_instances: int = 10,
                 startup_time_seconds: int = 60, idle_timeout_seconds: int = 300,
                 netconf_port: int = 830, ssh_port: int = 22, restconf_port: int = 443,
                 module_sets: list[str] = [],
                 instances: ?list[InstanceSpec] = None):
        self.name = name
        self.platform = platform
        self.container_image = container_image  # Optional for physical devices
        self.min_instances = min_instances
        self.max_instances = max_instances
        self.startup_time_seconds = startup_time_seconds  # Expected container startup time
        self.idle_timeout_seconds = idle_timeout_seconds  # When to shut down idle containers
        self.netconf_port = netconf_port  # NETCONF port inside container
        self.ssh_port = ssh_port  # SSH/CLI port inside container
        self.restconf_port = restconf_port  # RESTCONF port inside container
        self.module_sets = module_sets
        if instances is not None and len(instances) > 0:
            self.instances = instances
        else:
            self.instances = []
        # Runtime state (managed by Director)
        self.active_instances = 0
        self.available_instances = 0

    def uses_static_instances(self) -> bool:
        """Returns True if this platform uses static instances rather than dynamic scaling"""
        return len(self.instances) > 0

class SystemConfig(object):
    def __init__(self, platforms: list[PlatformConfig]):
        self.platforms = platforms

    def get_platform(self, name: str) -> ?PlatformConfig:
        for p in self.platforms:
            if p.name == name:
                return p
        return None

class ConvertRequest(object):
    def __init__(self, input: list[str], format: str, target_format: str, platform: str, module_set: str, cb: ?action(str) -> None = None):
        self.input = input
        self.format = format
        self.target_format = target_format
        self.platform = platform
        self.module_set = module_set
        self.platform_version = None  # For now, always None
        self.cb = cb  # Optional callback for async processing

    @staticmethod
    def from_json(data: dict[str, ?value]) -> ConvertRequest:
        # Get all required fields first
        if "input" not in data:
            raise ValueError("Missing required field: input")
        if "format" not in data:
            raise ValueError("Missing required field: format")
        if "target_format" not in data:
            raise ValueError("Missing required field: target_format")
        if "platform" not in data:
            raise ValueError("Missing required field: platform")

        input_val = data["input"]
        format_val = data["format"]
        target_format_val = data["target_format"]
        platform_val = data["platform"]
        module_set_val =  data.get_def("module_set", ALL_MODULE_SET)

        # Type check - input must be a list of strings (Acton lists are homogenous)
        if isinstance(input_val, list) and len(input_val) > 0 and isinstance(input_val[0], str):
            if isinstance(format_val, str) and isinstance(target_format_val, str) and isinstance(platform_val, str) and isinstance(module_set_val, str):
                return ConvertRequest(input_val, format_val, target_format_val, platform_val, module_set_val, None)
            else:
                raise ValueError("format, target_format, platform, and module_set must be strings")
        else:
            raise ValueError("input must be a non-empty list of strings")

actor Director(auth: WorldCap, proc_cap: process.ProcessCap, log_handler: logging.Handler):
    var device_manager: ?DeviceManager = None
    logh = logging.Handler("Director")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    def set_config(conf: SystemConfig):
        container_mgr = ContainerManager(proc_cap, log_handler)
        dm = DeviceManager(conf, container_mgr, auth, log_handler)
        dm.initialize_min_instances()
        device_manager = dm
        _log.info("Director initialized")


    def convert(request: ConvertRequest, callback: action(?(base_config: str, steps: list[(input: str, config: str, diff: str)]), ?Exception) -> None):
        """Process a conversion request"""
        _log.info("Director.convert called", {"input_format": request.format, "output_format": request.target_format, "platform": request.platform, "module_set": request.module_set, "input_count": len(request.input)})

        dm = device_manager
        if dm is not None:
            _log.info("DeviceManager found, requesting device")
            device = dm.get_device_for_request(request.platform)
            if device is not None:
                _log.info("Device acquired successfully")

                # Validate module_set if specified
                if request.module_set != "":
                    validation_error = device.validate_module_set(request.module_set)
                    if validation_error is not None:
                        _log.error("Module set validation failed", {"error": validation_error})
                        callback(None, Exception(validation_error))
                        return

                # Dispatch conversion request to the device
                _log.info("Dispatching conversion request to device")
                device.convert(request, callback)
            else:
                _log.error("No device available for platform", {"platform": request.platform})
                callback(None, Exception("No device available for %s" % request.platform))
        else:
            _log.error("Director not initialized - no DeviceManager")
            callback(None, Exception("Director not initialized"))


    def cli2xml(conf: str, cb):
        raise NotImplementedError()

    def xml2cli(conf: str):
        raise NotImplementedError()

    def get_instances() -> list[dict[str, ?value]]:
        """Get list of all instances for API response"""
        dm = device_manager
        if dm is not None:
            return dm.get_instance_info()
        else:
            return []

    def get_platforms() -> list[dict[str, ?value]]:
        """Get list of all configured platforms for API response"""
        platforms_data: list[dict[str, ?value]] = []
        dm = device_manager
        if dm is not None:
            config = dm.get_config()
            instance_info = dm.get_instance_info()
            for platform in config.platforms:
                # Count current instances - simplified for now
                total_instances = len(platform.instances) if platform.uses_static_instances() else 0
                available_instances = total_instances  # Simplified - assume all static instances are ready

                platform_data = {
                    "name": platform.name,
                    "platform": platform.platform,
                    "module_sets": platform.module_sets,
                    "scaling_type": "static" if platform.uses_static_instances() else "dynamic",
                    "total_instances": total_instances,
                    "available_instances": available_instances
                }

                # Add static instances info if applicable
                if platform.uses_static_instances():
                    instances_info = []
                    for spec in platform.instances:
                        spec_info = {
                            "id": spec.id,
                            "host": spec.host,
                            "netconf_port": spec.netconf_port,
                            "ssh_port": spec.ssh_port
                        }
                        desc = spec.description
                        if desc is not None:
                            spec_info["description"] = desc
                        instances_info.append(spec_info)
                    platform_data["instances"] = instances_info
                else:
                    # For dynamic platforms, show scaling configuration
                    platform_data["min_instances"] = platform.min_instances
                    platform_data["max_instances"] = platform.max_instances

                platforms_data.append(platform_data)
        return platforms_data

################################################################################
# MCP (Model Context Protocol) Implementation
################################################################################

# MCP Helper Functions

def _get_str(d: dict[str, ?value], k: str, dv: str = "") -> str:
    """Safely extract a string value from a dictionary, with default"""
    v = d.get(k)
    if isinstance(v, str):
        return v
    return dv

# JSON-RPC 2.0 error codes for MCP
MCP_PARSE_ERROR = -32700
MCP_INVALID_REQUEST = -32600
MCP_METHOD_NOT_FOUND = -32601
MCP_INVALID_PARAMS = -32602
MCP_INTERNAL_ERROR = -32603

class MCPError(object):
    """JSON-RPC 2.0 error for MCP"""
    def __init__(self, code: int, message: str, data: ?value = None):
        self.code = code
        self.message = message
        self.data = data

    def to_dict(self) -> dict[str, ?value]:
        result: dict[str, ?value] = {
            "code": self.code,
            "message": self.message
        }
        if self.data is not None:
            result["data"] = self.data
        return result

class MCPRequest(object):
    """JSON-RPC 2.0 request for MCP"""
    def __init__(self, id: ?value, method: str, params: dict[str, ?value]):
        self.id = id
        self.method = method
        self.params = params

    @staticmethod
    def from_json(data: dict[str, ?value]) -> MCPRequest:
        # Validate JSON-RPC 2.0 structure
        if "jsonrpc" not in data:
            raise ValueError("Missing jsonrpc field")
        jsonrpc_val = data["jsonrpc"]
        if not(isinstance(jsonrpc_val, str) and jsonrpc_val == "2.0"):
            raise ValueError("Invalid jsonrpc version, must be '2.0'")

        # id is optional for notifications
        id_val = data.get("id")

        # params is optional
        params_val = data.get("params")
        if params_val is not None and not isinstance(params_val, dict):
            raise ValueError("Params must be a dict or null")

        method_val = data.get("method")
        if method_val is not None:
            if isinstance(method_val, str):
                return MCPRequest(id_val, method_val, params_val if isinstance(params_val, dict) else {})
            raise ValueError("Method must be a string")
        raise ValueError("Missing method field")


class MCPResponse(object):
    """JSON-RPC 2.0 response for MCP"""
    def __init__(self, id: ?value, result: ?value = None, error: ?MCPError = None):
        self.id = id
        self.result = result
        self.error = error

    def to_dict(self) -> dict[str, ?value]:
        response: dict[str, ?value] = {
            "jsonrpc": "2.0",
            "id": self.id
        }

        self_error = self.error
        if self_error is not None:
            response["error"] = self_error.to_dict()
        else:
            response["result"] = self.result

        return response


# MCP Server Actor

actor MCPServer(convert_fn: action(ConvertRequest, action(?(base_config: str, steps: list[(input: str, config: str, diff: str)]), ?Exception) -> None) -> None,
                get_platforms_fn: action() -> list[dict[str, ?value]],
                get_instances_fn: action() -> list[dict[str, ?value]],
                log_handler: logging.Handler):
    """MCP Server actor that handles MCP protocol requests"""

    # Set up logging
    logh = logging.Handler("MCPServer")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    # Helper Functions for Response Handling

    def _send_success_response(request_id: ?value, result: ?value, respond: action(int, dict[str, str], str) -> None, context: str):
        """Send a successful MCP response with logging"""
        response = MCPResponse(request_id, result, None)
        response_json = json.encode(response.to_dict())
        _log.debug("MCP {context} response", {"context": context, "response": response_json})
        respond(200, {"Content-Type": "application/json"}, response_json)

    def _send_error_response(request_id: ?value, error_code: int, error_msg: str, respond: action(int, dict[str, str], str) -> None, context: str):
        """Send an error MCP response with logging"""
        error = MCPError(error_code, error_msg)
        response = MCPResponse(request_id, None, error)
        response_json = json.encode(response.to_dict())
        _log.debug("MCP {context} error response", {"context": context, "response": response_json})
        respond(200, {"Content-Type": "application/json"}, response_json)

    def _format_text_content(text: str) -> dict[str, ?value]:
        """Format text as MCP content object"""
        return {
            "content": [
                {
                    "type": "text",
                    "text": text
                }
            ]
        }

    def _validate_required_param(params: dict[str, ?value], key: str) -> ?str:
        """Validate and extract a required string parameter. Returns None if invalid."""
        val = params.get(key)
        if isinstance(val, str):
            return val
        return None

    def handle_initialize(request, respond: action(int, dict[str, str], str) -> None):
        """Handle MCP initialize request"""
        try:
            body_str = request.body.decode()
            _log.debug("MCP initialize request", {"body": body_str})
            mcp_req = MCPRequest.from_json(json.decode(body_str))

            # Return server info and capabilities
            result = {
                "protocolVersion": "2024-11-05",
                "serverInfo": {
                    "name": "netclics-mcp",
                    "version": "1.0.0"
                },
                "capabilities": {
                    "tools": {
                        "convert_config": {
                            "description": "Convert network configuration between formats",
                            "parameters": ["input_config", "format", "target_format", "platform"]
                        },
                        "list_platforms": {
                            "description": "List all available platforms",
                            "parameters": []
                        },
                        "list_instances": {
                            "description": "List all device instances and their status",
                            "parameters": []
                        }
                    }
                }
            }

            _send_success_response(mcp_req.id, result, respond, "initialize")
        except Exception as e:
            _log.error("MCP initialize error", {"error": str(e)})
            _send_error_response(None, MCP_INTERNAL_ERROR, str(e), respond, "initialize")

    def handle_tools_list(request, respond: action(int, dict[str, str], str) -> None):
        """Handle MCP tools/list request"""
        try:
            body_str = request.body.decode()
            _log.debug("MCP tools/list request", {"body": body_str})
            mcp_req = MCPRequest.from_json(json.decode(body_str))

            # Return list of available tools
            tools = [
                {
                    "name": "convert_config",
                    "description": "Convert network configuration between different formats",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "input_config": {"type": "array", "items": {"type": "string"}, "description": "List of configuration snippets to apply sequentially"},
                            "format": {"type": "string", "description": "Input format (cli, netconf, json)"},
                            "target_format": {"type": "string", "description": "Target format (cli, netconf, json, acton-adata, acton-gdata)"},
                            "platform": {"type": "string", "description": "Platform identifier"},
                            "module_set": {"type": "string", "description": "Name of predefined module-set"}
                        },
                        "required": ["input_config", "format", "target_format", "platform"]
                    }
                },
                {
                    "name": "list_platforms",
                    "description": "List all available NETCLICS platforms",
                    "inputSchema": {
                        "type": "object",
                        "properties": {}
                    }
                },
                {
                    "name": "list_instances",
                    "description": "List all NETCLICS device instances and their status",
                    "inputSchema": {
                        "type": "object",
                        "properties": {}
                    }
                }
            ]

            _send_success_response(mcp_req.id, {"tools": tools}, respond, "tools/list")
        except Exception as e:
            _log.error("MCP tools/list error", {"error": str(e)})
            _send_error_response(None, MCP_INTERNAL_ERROR, str(e), respond, "tools/list")

    def handle_tools_call(request, respond: action(int, dict[str, str], str) -> None):
        """Handle MCP tools/call request"""
        try:
            body_str = request.body.decode()
            _log.debug("MCP tools/call request", {"body": body_str})
            mcp_req = MCPRequest.from_json(json.decode(body_str))

            # Extract tool name and arguments from params
            tool_name = _get_str(mcp_req.params, "name")
            if tool_name == "":
                _send_error_response(mcp_req.id, MCP_INVALID_PARAMS, "Missing tool name", respond, "tools/call-missing-tool")
                return

            args = mcp_req.params.get_def("arguments", {})

            if tool_name == "convert_config" and isinstance(args, dict):
                _handle_convert_config(mcp_req.id, args, respond)
            elif tool_name == "list_platforms":
                _handle_list_platforms(mcp_req.id, respond)
            elif tool_name == "list_instances":
                _handle_list_instances(mcp_req.id, respond)
            else:
                _log.warning("Unknown tool requested", {"tool": tool_name})
                _send_error_response(mcp_req.id, MCP_METHOD_NOT_FOUND, "Unknown tool: " + tool_name, respond, "tools/call-unknown")

        except Exception as e:
            _log.error("MCP tools/call error", {"error": str(e)})
            _send_error_response(None, MCP_INTERNAL_ERROR, str(e), respond, "tools/call")

    def _handle_convert_config(request_id: ?value, args: dict[str, ?value], respond: action(int, dict[str, str], str) -> None):
        """Handle MCP convert_config tool call"""

        try:
            # Extract and validate parameters
            if "input_config" not in args:
                _send_error_response(request_id, MCP_INVALID_PARAMS, "Missing input_config parameter", respond, "convert_config-validation")
                return
            else:
                input_config = args["input_config"]
            if "format" not in args:
                _send_error_response(request_id, MCP_INVALID_PARAMS, "Missing format parameter", respond, "convert_config-validation")
                return
            else:
                format_val = args["format"]
            if "target_format" not in args:
                _send_error_response(request_id, MCP_INVALID_PARAMS, "Missing target_format parameter", respond, "convert_config-validation")
                return
            else:
                target_format = args["target_format"]
            if "platform" not in args:
                _send_error_response(request_id, MCP_INVALID_PARAMS, "Missing platform parameter", respond, "convert_config-validation")
                return
            else:
                platform = args["platform"]
            module_set = args.get_def("module_set", ALL_MODULE_SET)

            # Type checking - input_config must be a list of strings
            if isinstance(input_config, list) and len(input_config) > 0 and isinstance(input_config[0], str) and isinstance(format_val, str) and isinstance(target_format, str) and isinstance(platform, str) and isinstance(module_set, str):
                # All parameters are valid, create conversion request
                convert_req = ConvertRequest(input_config, format_val, target_format, platform, module_set, None)
            else:
                _send_error_response(request_id, MCP_INVALID_PARAMS, "input_config must be a non-empty list of strings, and other parameters must be strings", respond, "convert_config-validation")
                return

            # Define callback for when conversion completes
            def on_conversion_done(result: ?(base_config: str, steps: list[(input: str, config: str, diff: str)]), error: ?Exception):
                if error is None and result is not None:
                    content_parts = []

                    # Add base configuration
                    content_parts.append({
                        "type": "text",
                        "text": f"Conversion successful! Processed {len(result.steps)} configuration steps.\n\nBase configuration:\n{result.base_config}"
                    })

                    # Add each step's results
                    for i, step in enumerate(result.steps):
                        step_text = f"\n\n=== Step {i+1} ===\nInput: {step.input}\n\nConfiguration after step:\n{step.config}\n\nDiff from previous step:\n{step.diff}"
                        content_parts.append({
                            "type": "text",
                            "text": step_text
                        })

                    mcp_result = {
                        "content": content_parts
                    }

                    _send_success_response(request_id, mcp_result, respond, "convert_config-success")
                else:
                    error_msg = str(error) if error is not None else "Conversion failed"
                    _send_error_response(request_id, MCP_INTERNAL_ERROR, "Conversion failed: " + error_msg, respond, "convert_config-failure")

            # Execute conversion
            convert_fn(convert_req, on_conversion_done)

        except Exception as e:
            _send_error_response(request_id, MCP_INTERNAL_ERROR, str(e), respond, "convert_config")

    def _handle_list_platforms(request_id: ?value, respond: action(int, dict[str, str], str) -> None):
        """Handle MCP list_platforms tool call"""
        _log.debug("MCP list_platforms called")
        try:
            platforms_data = get_platforms_fn()

            # Format platforms for MCP response
            platforms_text = "Available platforms:\n"
            for platform in platforms_data:
                name = platform.get_def("name", "Unknown")
                platform_type = platform.get_def("platform", "Unknown type")
                available = platform.get_def("available_instances", 0)
                total = platform.get_def("total_instances", 0)
                platforms_text = platforms_text + "- {name} ({platform_type}) - {available}/{total} instances available\n"

            result = {
                "content": [
                    {
                        "type": "text",
                        "text": platforms_text
                    }
                ]
            }

            _send_success_response(request_id, result, respond, "list_platforms")

        except Exception as e:
            _send_error_response(request_id, MCP_INTERNAL_ERROR, str(e), respond, "list_platforms")

    def _handle_list_instances(request_id: ?value, respond: action(int, dict[str, str], str) -> None):
        """Handle MCP list_instances tool call"""
        _log.debug("MCP list_instances called")
        try:
            instances_data = get_instances_fn()

            # Format instances for MCP response
            instances_text = "Device instances:\n"
            for instance in instances_data:
                platform_name = instance.get_def("platform_name", "Unknown")
                state = instance.get_def("state", "Unknown")
                instance_id = instance.get_def("instance_id", "Unknown")
                instance_type = instance.get_def("instance_type", "Unknown")
                ip = instance.get_def("ip_address", "Unknown")
                instances_text = instances_text + "- {instance_id} ({platform_name}) - {state} [{instance_type}] @ {ip}"

                # Add module-set compilation status if available
                module_sets = instance.get("module_sets")
                if isinstance(module_sets, dict) and len(module_sets) > 0:
                    instances_text = instances_text + "\n    Module sets:"
                    for name, status in module_sets.items():
                        if isinstance(status, dict):
                            compiled = status.get_def("compiled", False)
                            error = status.get("error")
                            if isinstance(compiled, bool) and compiled:
                                instances_text = instances_text + "\n       {name}"
                            elif isinstance(error, str) and error != "Schema not compiled":
                                # Show error for failed compilations
                                error_preview = error[:50] + "..." if len(error) > 50 else error
                                instances_text = instances_text + "\n       {name} ({error_preview})"
                            else:
                                instances_text = instances_text + "\n       {name} (compiling)"

                instances_text = instances_text + "\n"

            result = {
                "content": [
                    {
                        "type": "text",
                        "text": instances_text
                    }
                ]
            }

            _send_success_response(request_id, result, respond, "list_instances")

        except Exception as e:
            _send_error_response(request_id, MCP_INTERNAL_ERROR, str(e), respond, "list_instances")

actor WebServ(listen_cap: net.TCPListenCap, http_port: ?int, director, log_handler: logging.Handler,
              https_port: ?int = None, tls_cert_pem: ?bytes = None, tls_key_pem: ?bytes = None):
    logh = logging.Handler("WebServ")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    # Create MCP server instance
    mcp = MCPServer(director.convert, director.get_platforms, director.get_instances, log_handler)

    def _on_http_accept(server):
        server.cb_install(_on_http_server_request, _on_http_server_error)

    def _on_https_accept(server):
        server.cb_install(_on_https_server_request, _on_https_server_error)

    def _handle_request(request, respond):
        _log.info("HTTP request received", {"method": request.method, "path": request.path})
        if request.path == "/api/v1/convert" and request.method == "POST":
            _log.info("Processing conversion request")
            try:
                body_str = request.body.decode()
                _log.debug("Request body", {"body": body_str})
                body_dict = json.decode(body_str)
                _log.debug("Parsed JSON", {"body_dict": str(body_dict)})

                # Parse the request using the from_json method
                convert_req = ConvertRequest.from_json(body_dict)
                _log.info("ConvertRequest created", {"input_format": convert_req.format, "output_format": convert_req.target_format, "platform": convert_req.platform})

                # Define callback for when conversion completes
                def on_conversion_done(result: ?(base_config: str, steps: list[(input: str, config: str, diff: str)]), error: ?Exception):
                    _log.debug("Conversion completed, preparing HTTP response")
                    if error is None and result is not None:
                        _log.info("Conversion successful")

                        steps = [{"input": step.input, "config": step.config, "diff": step.diff} for step in result.steps]
                        response = {
                            "success": True,
                            "base_config": result.base_config,
                            "steps": steps,
                            "platform": convert_req.platform,
                            "platform_version": "1.0"
                        }
                    else:
                        error_msg = str(error) if error is not None else "Conversion failed"
                        _log.error("Conversion failed", {"error": error_msg})
                        response = {
                            "success": False,
                            "error": error_msg,
                            "platform": convert_req.platform
                        }
                    response_str = json.encode(response)
                    _log.debug("Sending HTTP response", {"response_length": len(response_str)})
                    respond(200, {"Content-Type": "application/json"}, response_str)

                # Use Director's conversion logic with callback
                _log.debug("Calling Director.convert")
                director.convert(convert_req, on_conversion_done)
            except Exception as e:
                error_dict = {"success": False, "error": str(e)}
                error_str = json.encode(error_dict)
                respond(400, {"Content-Type": "application/json"}, error_str)
        # GET /api/v1/instances - List all running instances
        elif request.path == "/api/v1/instances" and request.method == "GET":
            # Get actual instances from director
            instances_data = director.get_instances()

            response = {
                "instances": instances_data,
                "total": len(instances_data)
            }
            respond(200, {"Content-Type": "application/json"}, json.encode(response))

        # GET /api/v1/platforms - List configured platforms
        elif request.path == "/api/v1/platforms" and request.method == "GET":
            # Get actual platforms from director
            platforms_data = director.get_platforms()

            response = {
                "platforms": platforms_data,
                "total": len(platforms_data)
            }
            respond(200, {"Content-Type": "application/json"}, json.encode(response))

        # MCP endpoint - single endpoint with JSON-RPC routing
        elif request.path == "/mcp" and request.method == "POST":
            try:
                body_str = request.body.decode()
                _log.debug("MCP request received", {"body": body_str})
                body_dict = json.decode(body_str)
                method = _get_str(body_dict, "method")
                _log.debug("MCP method", {"method": method})

                if method == "initialize":
                    mcp.handle_initialize(request, respond)
                elif method == "tools/list":
                    mcp.handle_tools_list(request, respond)
                elif method == "tools/call":
                    mcp.handle_tools_call(request, respond)
                else:
                    # Unknown method
                    _log.warning("Unknown MCP method", {"method": method})
                    error = MCPError(MCP_METHOD_NOT_FOUND, "Unknown method: " + str(method))
                    response = MCPResponse(body_dict.get("id"), None, error)
                    response_json = json.encode(response.to_dict())
                    _log.debug("MCP unknown method response", {"response": response_json})
                    respond(200, {"Content-Type": "application/json"}, response_json)
            except Exception as e:
                _log.error("MCP routing error", {"error": str(e)})
                error = MCPError(MCP_INTERNAL_ERROR, str(e))
                response = MCPResponse(None, None, error)
                response_json = json.encode(response.to_dict())
                _log.debug("MCP routing error response", {"response": response_json})
                respond(200, {"Content-Type": "application/json"}, response_json)

        else:
            respond(404, {"Content-Type": "application/json"}, json.encode({"error": "Not found"}))

    def _on_http_server_request(server, request, respond):
        _handle_request(request, respond)

    def _on_https_server_request(server, request, respond):
        _handle_request(request, respond)

    def _on_http_server_error(server, error):
        _log.error("HTTP server error", {"error": error})

    def _on_https_server_error(server, error):
        _log.error("HTTPS server error", {"error": error})

    def _on_http_listen_error(listener, error):
        _log.error("HTTP listen error", {"error": error})

    def _on_https_listen_error(listener, error):
        _log.error("HTTPS listen error", {"error": error})

    var http_server: ?http.Listener = None
    if http_port is not None:
        http_server = http.Listener(listen_cap, "0.0.0.0", http_port, _on_http_accept, _on_http_listen_error)
    else:
        _log.warning("HTTP endpoint disabled")

    var https_server: ?http.TLSListener = None
    if https_port is not None and tls_cert_pem is not None and tls_key_pem is not None:
        https_server = http.TLSListener(
            listen_cap,
            "0.0.0.0",
            https_port,
            tls_cert_pem,
            tls_key_pem,
            _on_https_accept,
            _on_https_listen_error
        )
    else:
        _log.warning("HTTPS endpoint disabled")


def get_default_config() -> SystemConfig:
    return SystemConfig([
        # Juniper cRPD platform - dynamically managed containers
#        PlatformConfig(
#            name="crpd",
#            version="24.4R1.9",
#            container_image="ghcr.io/orchestron-orchestrator/respnet/crpd:24.4R1.9",
#            min_instances=1,
#            max_instances=3
#        ),
        # Local cRPD static instance
        PlatformConfig(
            name="crpd 24.4R1.9-local",
            platform="junos",
            instances=[
                InstanceSpec(
                    id="local-crpd",
                    host="127.0.0.1",
                    netconf_port=42830,
                    ssh_port=42022,
                    restconf_port=32774,
                    username="clab",
                    password="clab@123",
                    description="Local cRPD instance"
                )
            ]
        ),
        # Local Cisco IOS XRd static instance
        PlatformConfig(
            name="iosxrd 24.1.1-local",
            platform="cisco_iosxr",
            module_sets=["cisco-xr-classic", "cisco-xr-unified-model"],
            instances=[
                InstanceSpec(
                    id="local-iosxrd",
                    host="127.0.0.1",
                    netconf_port=43830,
                    ssh_port=43022,
                    restconf_port=32775,
                    username="clab",
                    password="clab@123",
                    description="Local IOS XRd instance"
                )
            ]
        ),
        PlatformConfig(
            name="iosxrd 25.3.1-local",
            platform="cisco_iosxr",
            module_sets=["cisco-xr-classic", "cisco-xr-unified-model"],
            instances=[
                InstanceSpec(
                    id="local-iosxrd",
                    host="127.0.0.1",
                    netconf_port=45830,
                    ssh_port=45022,
                    restconf_port=32775,
                    username="clab",
                    password="clab@123",
                    description="Local IOS XRd instance"
                )
            ]
        ),
        # Local Cisco IOS XE static instance
        PlatformConfig(
            name="iosxe 17.18.02-local",
            platform="cisco_iosxe",
            module_sets=["cisco-xe-native"],
            instances=[
                InstanceSpec(
                    id="local-iosxe",
                    host="127.0.0.1",
                    netconf_port=44830,
                    ssh_port=44022,
                    restconf_port=32776,
                    username="vrnetlab",
                    password="VR-netlab9",
                    description="Local IOS XE instance"
                )
            ]
        ),
        # Example platform with static instances (could be physical devices, VMs, etc.)
#        PlatformConfig(
#            name="junos",
#            version="21.4R1",
#            static_instances=[
#                InstanceSpec(
#                    instance_id="lab-router-1",
#                    host="192.168.1.10",
#                    netconf_port=830,
#                    ssh_port=22,
#                    username="admin",
#                    description="Lab router #1"
#                ),
#                InstanceSpec(
#                    instance_id="lab-router-2",
#                    host="192.168.1.11",
#                    netconf_port=830,
#                    ssh_port=22,
#                    username="admin",
#                    description="Lab router #2"
#                )
#            ]
#        )
    ])

actor main(env: Env):
    listen_cap = net.TCPListenCap(net.TCPCap(net.NetCap(env.cap)))
    proc_cap = process.ProcessCap(env.cap)

    def _parse_args():
        p = argparse.Parser()
        p.add_option("http-port", "int", default=8080, help="HTTP listen port (set to 0 to disable)")
        p.add_option("https-port", "int", default=0, help="HTTPS listen port (set to 0 to disable)")
        p.add_option("tls-cert", "str", default="", help="Path to TLS certificate PEM file")
        p.add_option("tls-key", "str", default="", help="Path to TLS private key PEM file")
        return p.parse(env.argv)

    maybe_args = None
    try:
        maybe_args = _parse_args()
    except argparse.PrintUsage as exc:
        print(exc.error_message)
        await async env.exit(0)
    except argparse.ArgumentError as exc:
        print(exc.error_message, err=True)
        await async env.exit(1)

    args = expect(maybe_args, "parsed args")

    http_port = args.get_int("http-port")
    https_port = args.get_int("https-port")
    tls_cert_path = args.get_str("tls-cert")
    tls_key_path = args.get_str("tls-key")

    # Load configuration
    config = get_default_config()
    # Create logging handler
    log_handler = logging.Handler(None)
    log_handler.add_sink(logging.StdoutSink())
    log_handler.set_output_level(logging.TRACE)  # Set maximum debugging for SSH/NETCONF

    # Create logger for main
    logh = logging.Handler("main")
    logh.set_handler(log_handler)
    _log = logging.Logger(logh)

    tls_cert_pem: ?bytes = None
    tls_key_pem: ?bytes = None
    if https_port != 0:
        if tls_cert_path != "" and tls_key_path != "":
            file_cap = file.FileCap(env.cap)
            read_cap = file.ReadFileCap(file_cap)
            try:
                cert_reader = file.ReadFile(read_cap, tls_cert_path)
                tls_cert_pem = cert_reader.read()
                cert_reader.close()
                key_reader = file.ReadFile(read_cap, tls_key_path)
                tls_key_pem = key_reader.read()
                key_reader.close()
                _log.info("Loaded TLS certificate and key", {"https_port": https_port, "cert_path": tls_cert_path, "key_path": tls_key_path})
            except Exception as e:
                print("ERROR: Failed to load TLS certificate/key (cert: {tls_cert_path}, key: {tls_key_path}): {str(e)}", err=True)
                env.exit(1)
        else:
            print("ERROR: HTTPS port {https_port} configured but --tls-cert and --tls-key were not both provided", err=True)
            env.exit(1)

    _log.info("Loaded platform configurations", {"platform_count": len(config.platforms)})

    director = Director(env.cap, proc_cap, log_handler)
    director.set_config(config)
    webs = WebServ(listen_cap, http_port if http_port > 0 else None, director, log_handler, https_port if https_port > 0 else None, tls_cert_pem, tls_key_pem)
    if https_port is not None and tls_cert_pem is not None and tls_key_pem is not None:
        _log.info("NETCLICS started", {"http_port": http_port, "https_port": https_port})
    else:
        _log.info("NETCLICS started", {"http_port": http_port})
